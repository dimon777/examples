{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "complains_url=\"https://data.cityofnewyork.us/api/views/erm2-nwe9/rows.csv\"\n",
    "pop_byzip_url = \"https://data.cityofnewyork.us/resource/rreq-n6zk.csv\"\n",
    "pop_byborough_url = \"https://data.cityofnewyork.us/api/views/h2bk-zmw6/rows.csv?accessType=DOWNLOAD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for some reason pandas ignores nrows() when reading from URL so we use bash magic to expolore schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++ COMPLAINS ++++++++++++++++++++++++++++++++\n",
      "Unique Key,Created Date,Closed Date,Agency,Agency Name,Complaint Type,Descriptor,Location Type,Incident Zip,Incident Address,Street Name,Cross Street 1,Cross Street 2,Intersection Street 1,Intersection Street 2,Address Type,City,Landmark,Facility Type,Status,Due Date,Resolution Description,Resolution Action Updated Date,Community Board,BBL,Borough,X Coordinate (State Plane),Y Coordinate (State Plane),Open Data Channel Type,Park Facility Name,Park Borough,Vehicle Type,Taxi Company Borough,Taxi Pick Up Location,Bridge Highway Name,Bridge Highway Direction,Road Ramp,Bridge Highway Segment,Latitude,Longitude,Location\n",
      "39903778,08/02/2018 12:00:00 AM,08/07/2018 12:00:00 AM,DOHMH,Department of Health and Mental Hygiene,Rodent,Condition Attracting Rodents,3+ Family Apt. Building,10075,246 EAST   80 STREET,EAST   80 STREET,3 AVENUE,2 AVENUE,,,ADDRESS,NEW YORK,,N/A,Closed,09/01/2018 05:25:39 PM,The Department of Health and Mental Hygiene will review your complaint to determine appropriate action.  Complaints of this type usually result in an inspection.  Please call 311 in 30 days from the date of your complaint for status,08/07/2018 12:00:00 AM,08 MANHATTAN,1015250021,MANHATTAN,996512,221454,ONLINE,Unspecified,MANHATTAN,,,,,,,,40.77450788823179,-73.9557282051142,\"(40.77450788823179, -73.9557282051142)\"\n",
      "++++++++++++++++++++++++ POPULATION BY ZIP CODES ++++++++++++++++++++++++\n",
      "\"count_american_indian\",\"count_asian_non_hispanic\",\"count_black_non_hispanic\",\"count_citizen_status_total\",\"count_citizen_status_unknown\",\"count_ethnicity_total\",\"count_ethnicity_unknown\",\"count_female\",\"count_gender_total\",\"count_gender_unknown\",\"count_hispanic_latino\",\"count_male\",\"count_nreceives_public_assistance\",\"count_other_citizen_status\",\"count_other_ethnicity\",\"count_pacific_islander\",\"count_participants\",\"count_permanent_resident_alien\",\"count_public_assistance_total\",\"count_public_assistance_unknown\",\"count_receives_public_assistance\",\"count_us_citizen\",\"count_white_non_hispanic\",\"jurisdiction_name\",\"percent_american_indian\",\"percent_asian_non_hispanic\",\"percent_black_non_hispanic\",\"percent_citizen_status_total\",\"percent_citizen_status_unknown\",\"percent_ethnicity_total\",\"percent_ethnicity_unknown\",\"percent_female\",\"percent_gender_total\",\"percent_gender_unknown\",\"percent_hispanic_latino\",\"percent_male\",\"percent_nreceives_public_assistance\",\"percent_other_citizen_status\",\"percent_other_ethnicity\",\"percent_pacific_islander\",\"percent_permanent_resident_alien\",\"percent_public_assistance_total\",\"percent_public_assistance_unknown\",\"percent_receives_public_assistance\",\"percent_us_citizen\",\"percent_white_non_hispanic\"\n",
      "\"0\",\"3\",\"21\",\"44\",\"0\",\"44\",\"0\",\"22\",\"44\",\"0\",\"16\",\"22\",\"24\",\"0\",\"3\",\"0\",\"44\",\"2\",\"44\",\"0\",\"20\",\"42\",\"1\",\"10001\",\"0\",\"0.07\",\"0.48\",\"100\",\"0\",\"100\",\"0\",\"0.5\",\"100\",\"0\",\"0.36\",\"0.5\",\"0.55\",\"0\",\"0.07\",\"0\",\"0.05\",\"100\",\"0\",\"0.45\",\"0.95\",\"0.02\"\n",
      "+++++++++++++++++++++++++ POPULATION BY BOROUGH +++++++++++++++++++++++++\n",
      "Borough,Population\n",
      "Brooklyn,4970026\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$complains_url\" \"$pop_byzip_url\" \"$pop_byborough_url\"\n",
    "echo \"++++++++++++++++++++++++++++++ COMPLAINS ++++++++++++++++++++++++++++++++\"\n",
    "wget -qO- $1 | head -2\n",
    "\n",
    "echo \"++++++++++++++++++++++++ POPULATION BY ZIP CODES ++++++++++++++++++++++++\"\n",
    "wget -qO- $2 | head -2\n",
    "\n",
    "echo \"+++++++++++++++++++++++++ POPULATION BY BOROUGH +++++++++++++++++++++++++\"\n",
    "wget -qO- $3 | head -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load files locally\n",
    "this may not be very efficient, but standard Pandas `read_csv` on URL is loading whole dataset into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$complains_url\" \"$pop_byzip_url\" \"$pop_byborough_url\"\n",
    "echo \"++++++++++++++++++++++++++++++ COMPLAINS ++++++++++++++++++++++++++++++++\"\n",
    "wget -O data/complains.csv $1\n",
    "\n",
    "echo \"++++++++++++++++++++++++ POPULATION BY ZIP CODES ++++++++++++++++++++++++\"\n",
    "wget -O data/popul_byzip.csv $2\n",
    "\n",
    "echo \"+++++++++++++++++++++++++ POPULATION BY BOROUGH +++++++++++++++++++++++++\"\n",
    "wget -O data/popul_byborough.csv $3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data loading & exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "complains_f = \"data/complains.csv\"\n",
    "pop_byzip_f = \"data/popul_by_zip.csv\"\n",
    "pop_byborough_f = \"data/popul_by_borough.csv\"\n",
    "chunksize = 100000\n",
    "year=2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2e09ffbf559a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Unique Key'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Incident Zip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Borough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'City'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Complaint Type'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"N/A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"N/A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"N/A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"N/A\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                          low_memory=False, iterator=True, chunksize=chunksize):\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Created Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Borough'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Unspecified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# lambda: c = chunk.pipe(lambda x: x[(pd.to_datetime(x['Created Date']).dt.year == year) & (chunk['Borough'] != \"Unspecified\")])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 424\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    425\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# Override compression based on Content-Encoding header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readall_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_readall_chunked\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m    935\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m                   self.__class__)\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \"\"\"\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for chunk in pd.read_csv(complains_url, skipinitialspace=True, index_col='Unique Key',\n",
    "                         usecols=['Unique Key','Created Date','Borough','Incident Zip','City','Complaint Type'],\n",
    "                         dtype={'Unique Key':int,'Incident Zip':int,'Borough':'category','City':'category','Complaint Type':'category'},\n",
    "                         na_values=[0, \"0\", \"N/A\", \"N/A\", 0, \"N/A\", \"N/A\"],\n",
    "                         low_memory=False, iterator=True, chunksize=chunksize):\n",
    "    c = chunk[(pd.to_datetime(chunk['Created Date']).dt.year == year) & (chunk['Borough'] != \"Unspecified\")]\n",
    "# lambda: c = chunk.pipe(lambda x: x[(pd.to_datetime(x['Created Date']).dt.year == year) & (chunk['Borough'] != \"Unspecified\")])\n",
    "    chunks.append(c)\n",
    "    print(\"Added %d rows\" %(len(c)))\n",
    "          \n",
    "df = pd.concat(chunks, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "chunks = []\n",
    "for chunk in pd.read_csv(io.StringIO(r.content.decode('utf-8')), skipinitialspace=True, index_col='Unique Key',\n",
    "                         usecols=['Unique Key','Created Date','Borough','Incident Zip','City','Complaint Type'],\n",
    "                         dtype={'Unique Key':int,'Incident Zip':int,'Borough':'category','City':'category','Complaint Type':'category'},\n",
    "                         na_values=[0, \"0\", \"N/A\", \"N/A\", 0, \"N/A\", \"N/A\"],\n",
    "                         low_memory=False, iterator=True, chunksize=chunksize):\n",
    "    # chunks.append(chunk[(pd.to_datetime(chunk['Created Date']).dt.year == year) & (chunk['Borough'] != \"Unspecified\")])\n",
    "    # c = chunk[(pd.to_datetime(chunk['Created Date']).dt.year == year) & (chunk['Borough'] != \"Unspecified\")]\n",
    "    c = chunk.pipe(lambda x: x[(pd.to_datetime(x['Created Date']).dt.year == year) & (chunk['Borough'] != \"Unspecified\")])\n",
    "    chunks.append(c)\n",
    "    print(\"Added %d rows\" %(len(c)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 0\n",
    "chunks = []\n",
    "for lines in r.iter_lines(decode_unicode='utf-8'):\n",
    "    print(iters)\n",
    "    if (iters > 0):\n",
    "        df = pd.read_csv(StringIO(lines), usecols=[0,1,5,8,16,25], index_col=0, header=None,\n",
    "                         names=['Unique Key','Created Date','Complaint Type','Incident Zip','City','Borough'],\n",
    "                         dtype={'Incident Zip': int})\n",
    "    else:\n",
    "        df = pd.read_csv(StringIO(lines), header=0, usecols=[0,1,5,8,16,25], index_col=0,\n",
    "                         names=['Unique Key','Created Date','Complaint Type','Incident Zip','City','Borough'],\n",
    "                         dtype={'Incident Zip': int})\n",
    "    \n",
    "    chunks.append(df)\n",
    "    iters += 1\n",
    "    if iters == 10:\n",
    "        break\n",
    "\n",
    "df = pd.concat(chunks, axis=0, ignore_index=False, sort=False)\n",
    "#df.to_csv(\"data/rows_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrlReader:\n",
    "    def __init__(self, url, nrows):\n",
    "        self.url = url\n",
    "        self.nrows = nrows\n",
    "        \n",
    "    def read():\n",
    "        lines = []\n",
    "        with closing(requests.get(url, stream=True)) as r:\n",
    "            f = (line.decode('utf-8') for line in r.iter_lines())\n",
    "            yield f\n",
    "    \n",
    "#def get_url(url):\n",
    "#    with closing(requests.get(url, stream=True)) as r:\n",
    "#        f = (line.decode('utf-8') for line in r.iter_lines())\n",
    "#        reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "#        yield reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_df=pd.read_csv(StringIO(r.text), skipinitialspace=True, index_col='Unique Key', usecols=['Unique Key','Created Date','Borough','Incident Zip','City','Complaint Type'], low_memory=False, iterator=True, chunksize=chunksize)\n",
    "#df = pd.concat([chunk[(pd.to_datetime(chunk['Created Date']).dt.year == year) & (chunk['Borough'] != \"Unspecified\")] for chunk in iter_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_borough = df[['Borough']].drop_duplicates()\n",
    "df_borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Borough'])['Borough'].count().reset_index(name='cnt').sort_values(by='cnt', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compl_type = df[['Complaint Type']].drop_duplicates()\n",
    "df_compl_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borough == Unspecified is less then 0.5% of all records so we are going to drop those records from the DataFrame\n",
    "# This also can be done at a loading time (see above)\n",
    "df = df[df['Borough'].map(lambda x: str(x) != \"Unspecified\")]\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Borough'])['Borough'].count().reset_index(name='cnt').sort_values(by='cnt', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are few complains where City or/and Zip is Nan:\n",
    "city_null = df['City'].isnull()\n",
    "zip_null = df['Zip'].isnull()\n",
    "\n",
    "# Select these cases:\n",
    "df[zip_null | city_null]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Zip'].notnull() | df['City'].notnull()]\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Consider only the 10 most common overall complaint types. For each borough, how many of each of those 10 types were there in 2017?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First top 10 complains types:\n",
    "top10_complains = df.groupby(['Complaint Type'])['Complaint Type'].count().reset_index(name='cnt').sort_values(by='cnt', ascending=False).head(n=10)\n",
    "top10_complains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged_with_top10 = pd.merge(top10_complains, df, on='Complaint Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each borough, how many of each of those 10 types were there in 2017?\n",
    "top10_borough_complains = all_merged_with_top10.groupby(['Borough','Complaint Type'])['Complaint Type'].count().reset_index(name='cnt').sort_values(by=['Borough','cnt'], ascending=[True, False])\n",
    "top10_borough_complains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 complains by each borough (this contains exaclt 10 rows per borough):\n",
    "top10_complains_by_borough = df.groupby(['Borough','Complaint Type'])['Complaint Type'].count().groupby(level='Borough').nlargest(10).reset_index(level=0, drop=True)\n",
    "top10_complains_by_borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Consider only the 10 most common overall complaint types. For the 10 most populous zip codes, how many of each of those 10 types were there in 2017?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Find top 10 mst populous zip codes\n",
    "top10_zip_pop = pd.read_csv(pop_byzip_url, skipinitialspace=True, usecols=['jurisdiction_name','count_participants']).sort_values(by=['count_participants'], ascending=[False]).head(10)\n",
    "top10_zip_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.merge(top10_zip_pop, df, left_on=\"jurisdiction_name\", right_on='Zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_complains_by_zip = t_df.groupby(['Zip','Complaint Type'])['Complaint Type'].count().groupby(level='Zip').nlargest().reset_index(level=0, drop=True)\n",
    "top10_complains_by_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Considering all complaint types. Which boroughs are the biggest \"complainers\" relative to the size of the population in 2017 Meaning, calculate a complaint-index that adjusts for population of the borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_popul = pd.read_csv(pop_byborough_url, skipinitialspace=True).apply(lambda x: x.astype(str).str.upper())\n",
    "borough_popul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_compl = df.groupby(['Borough'])['Borough'].count().reset_index(name='complains')\n",
    "borough_compl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_compl_per_popul_unit = pd.merge(borough_compl, borough_popul, on=\"Borough\")\n",
    "borough_compl_per_popul_unit['compl_per_1m_popul'] = 1000000*borough_compl_per_popul_unit['complains']/borough_compl_per_popul_unit['Population']\n",
    "borough_compl_per_popul_unit = borough_compl_per_popul_unit.sort_values(by=['compl_per_1m_popul'], ascending=[False])\n",
    "borough_compl_per_popul_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11219'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "s = \"11219-0283\"\n",
    "s[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11219"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(s[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11219-0283'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.replace(r'-[\\s\\S]*$', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11219'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
